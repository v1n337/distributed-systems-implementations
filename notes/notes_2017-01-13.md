# U-Net

Network latency = dominating factor for workloads dealing with huge data
Processing time = dominating factor for smaller workloads

## Motivation
* Software being the bottleneck once the network speeds increase
* Application specific-protocols could be used to communicate with the NI

## Objective
* Low latency and flexible architecture

## Prior Implementation
* All communication was routed through the kernel
* Kernel also muxes/demuxes the incoming/outgoing data

## Unet Stack
* What's different in UNet? = Bypass the kernel and allow applications to access the NI
* Driver for the network interface card to ensure that the received data is sent to the application that requested it
* Components
    * Communication segment - data descriptors stored here
    * Send, receive, free queues
* Sending data
    * Copy data to communication segement
    * Add data descriptor to the send queue
    * NIC pulls descriptor, gets message from comm. segment and sends the message
* Receiving data
    * Pull wire (ref. https://en.wikipedia.org/wiki/Wire\_protocol) for msg
    * Demux to the proper end-point - each end-point has a specific channel ID
    * Get descriptor from the free queue - (if the free queue is empty, drop packets)
    * Put data in the comm. segment
    * Put descriptor in the receive queue
    * Application notification
    * Application reads message
    * Put the descriptor in the free queue


## DMA
* Pinned memory (in the context of DMA) - memory that is unswappable to disk
* All memory cannot be pinned as it's a limited resource
* DMA address is smaller?

## Optimizations
* Comm. segment pinned in memory
* Free queue on the NI
* Send queue on the NI
* Receive queue on memory

## Emulated end-points
* For applications that don't need the application specific optimization benefits of an end-point
* Kernel handles the muxing/demuxing for emulated end-points

## Zero-copy vs True zero-copy
* True zero copy is problematic, because the NI needs an MMU to be able to address physical memory

## UAM (U-Net Active messages)
* Uses windows of buffers

### Sending messages
* Read all received messages (to check if there are any received acknowledgements)
* Push message to send queue
* If the send queue is full:
    * Pull incoming messages
    * Timeout/retry

### Receiving messages
* Consume the receive queue
* Acknowledge each of them
* Put the descriptor in the free queue, to free up memory in the communication segment





